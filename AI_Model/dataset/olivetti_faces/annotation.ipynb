{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olivetti Faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # load environment variables\n",
    "import time\n",
    "import os\n",
    "import base64\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "AI_MODEL_PATH = os.path.abspath(os.path.join(os.path.curdir, os.pardir, os.pardir))\n",
    "sys.path.append(AI_MODEL_PATH)\n",
    "from image_preprocessing import visualize_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/serkanpeldek/face-recognition-on-olivetti-dataset\n",
    "olivetti_faces_data = np.load('olivetti_faces.npy')\n",
    "olivetti_faces_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "visualize_image(olivetti_faces_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 400 digitized images of human faces, each of 64 x 64 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Google Gemini API\n",
    "client = genai.Client(api_key=os.environ.get('GOOGLE_GEMINI_API_KEY'))\n",
    "\n",
    "# Annotate an image with Google Gemini: \n",
    "# - is_human: boolean\n",
    "# - emotion: string\n",
    "def generate_prompt(filename: str = 'annotate-image-prompt.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"Analyze the facial expression in this image.\\n\")\n",
    "        file.write(\"Please provide a JSON object with the following fields:\\n\")\n",
    "        file.write(\"- is_human: boolean\\n\")\n",
    "        file.write(\"- emotion: string\\n\")\n",
    "        file.write(\"The scope of Emotions:\\n\")\n",
    "        file.write(\"1. Angry\\n\")\n",
    "        file.write(\"2. Fear\\n\")\n",
    "        file.write(\"3. Happy\\n\")\n",
    "        file.write(\"4. Neutral\\n\")\n",
    "        file.write(\"5. Sad\\n\")\n",
    "        file.write(\"6. Surprise\\n\")\n",
    "        file.write(\"7. Stress\\n\\n\")\n",
    "        file.write(\"Examples:\\n\")\n",
    "        file.write(\"{\\n\")\n",
    "        file.write(\"  \\\"is_human\\\": true,\\n\")\n",
    "        file.write(\"  \\\"emotion\\\": \\\"Happy\\\"\\n\")\n",
    "        file.write(\"}\\n\")\n",
    "    \n",
    "\n",
    "def annotate_images_with_gemini(images, prompt: str):\n",
    "    annotations = []\n",
    "    for image in images:\n",
    "        # Convert the image to a format suitable for the API (e.g., base64 encoding)\n",
    "        image_data = (image * 255).astype(np.uint8)  # Convert to uint8\n",
    "        image_data = image_data.reshape(64, 64)  # Reshape to 64x64 if needed\n",
    "        _, buffer = cv2.imencode('.jpg', image_data)\n",
    "        image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "        # Prepare the payload for the Gemini API\n",
    "        payload = {\n",
    "            \"model\": \"gemini-2.0-flash\",\n",
    "            \"contents\": image_base64,\n",
    "            \"parameters\": {\n",
    "                \"prompt\": prompt\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Call the Gemini API\n",
    "        response = client.models.generate_content(payload)\n",
    "\n",
    "        # Assuming the response object has a 'result' attribute\n",
    "        if hasattr(response, 'result'):\n",
    "            annotations.append(response.result)\n",
    "        else:\n",
    "            annotations.append({'is_human': False, 'emotion': 'Unknown'})\n",
    "        \n",
    "        time.sleep(5)  # Sleep for 5 seconds to avoid rate limiting\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the prompt file\n",
    "generate_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Annotate images with Gemini\n",
    "annotations: list[dict] = annotate_images_with_gemini(\n",
    "    images=olivetti_faces_data, \n",
    "    prompt='annotate-image-prompt.txt'\n",
    ")\n",
    "IS_HUMAN_LABEL = []\n",
    "EMOTION_LABEL = []\n",
    "\n",
    "for annotation in annotations:\n",
    "    IS_HUMAN_LABEL.append(annotation['is_human'] if annotation['is_human'] is not None else False)\n",
    "    EMOTION_LABEL.append(annotation['emotion'] if annotation['emotion'] is not None else 'Unknown')\n",
    "\n",
    "# Save Labels to Files\n",
    "LABEL_DIR = os.path.join(AI_MODEL_PATH, 'label')\n",
    "if not os.path.exists(LABEL_DIR):\n",
    "    os.makedirs(LABEL_DIR)\n",
    "\n",
    "IS_HUMAN_LABEL_FILEPATH = os.path.join(LABEL_DIR, 'is_human_label.npy')\n",
    "EMOTION_LABEL_FILEPATH = os.path.join(LABEL_DIR, 'emotion_label.npy')\n",
    "np.save(IS_HUMAN_LABEL_FILEPATH, IS_HUMAN_LABEL)\n",
    "np.save(EMOTION_LABEL_FILEPATH, EMOTION_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(IS_HUMAN_LABEL) == len(EMOTION_LABEL) == olivetti_faces_data.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
